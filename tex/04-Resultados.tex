% ----------------------------------------------------------------------- %
% Arquivo: 04-Resultados.tex
% ----------------------------------------------------------------------- %
\chapter{Treinamento da Rede Neural para Detecção e localização de Defeitos em Placas de Circuito Impresso} \label{cap:treinamento}
%FALTA ESCERVER ESSA PARTE.
%Nesse capítulo serão discutidas a escolha e as etapas de preparação do \textit{dataset} para o treinamento, detalhes de configurações da rede neural utilizada e os resultados obtidos.

\section{Seleção da Rede Neural e do \textit{Framework} para o Treinamento} \label{cap:treinamento-rn}

Defeitos em placas de circuito impresso ocupam pequenas regiões da PCI, de forma que a proporção entre a área do objeto a ser detectado e a imagem inteira é muito pequena. Sendo assim, a escolha da rede neural deve considerar um bom desempenho para detecção de pequenos objetos. Segundo \citeonline{ref:Redmon-Farhadi}, a partir da versão três, a YOLO apresentou uma melhor performance para esse tipo de detecção, sendo recomendada para essa aplicação por \citeonline{ref:Valenti-et-al}, quando o tempo de treinamento não é tão relevante. Já a versão quatro da YOLO apresenta melhor desempenho para o treinamento em GPUs quando comparada a sua versão anterior.

Sendo assim, a rede neural escolhida para o treinamento da detecção de defeitos em PCIs foi a YOLO em sua quarta versão, proposta por \citeonline{ref:Bochkovskiy-Wang-Liao} em conjunto com \textit{framework} Darknet, que possui funções de cálculo das métricas de avaliação, desenho das caixas delimitadoras, entre outras.

\section{Seleção do Conjunto de Dados} \label{cap:treinamento-dataset}

Para a detecção e classificação de objetos, o conjunto de dados escolhido deve incluir além das imagens, a localização e classificação dos objetos de interesse.
O \textit{Dataset} escolhido para a detecção e localização de defeitos em PCIs é o \textit{HRIPCB: a challenging dataset for PCB defects detection and classification}, proposto por \citeonline{ref:Huang-et-al}.

As imagens das placas são capturadas por uma câmera do tipo industrial com dezesseis megapixel de resolução equipada com um sensor C-MOS \cite{ref:Huang-et-al}. Após a captura e ajustes, seis tipos de defeitos são adicionados manualmente em um \textit{software} de edição de imagens, onde cada imagem contém de dois a seis defeitos da mesma categoria em diferentes lugares da placa \cite{ref:Huang-et-al}. A distribuição dos defeitos está na \autoref{tab:treinamento-dataset}.

\begin{table}[!h]
\begin{center}
\caption{Distribuição dos defeitos no conjunto de dados HRIPCB.}
\label{tab:treinamento-dataset}
\begin{tabular}{ccc}
\toprule
\textbf{Tipo do Defeito} & \textbf{Número de Imagens} & \textbf{Quantidade Total de Defeitos} \\
\midrule \midrule
Falta de Estanho    & 115   & 497 \\
Falta de Cobre      & 115   & 492 \\
Circuito Aberto     & 116   & 482 \\
Curto-Circuito      & 116   & 491 \\
Excesso de Cobre    & 115   & 488 \\
Trilha Desconectada & 116   & 503 \\
\bottomrule
\end{tabular}
\indentedfont[0.96\textwidth]{\citeonline{ref:Huang-et-al}}
\end{center}
\end{table}

Para cada uma das imagens, existe um arquivo com extensão \textit{.xml} que mapeia as informações das caixas delimitadoras de cada defeito. Um exemplo desse arquivo está no \autoref{apendice:hripcb-xml}.
As anotações do HRIPCB não estão normalizadas e e são mapeadas em coordenadas cartesianas em pixeis $x_{min}$, $x_{max}$, que variam entre zero e a largura da imagem e $y_{min}$, $y_{max}$, que variam entre zero e a altura da imagem, conforme a \autoref{fig:resultados-hripcb-notacao}.

\begin{figure}[h!] %H
  \centering
  \caption{Anotações das caixas delimitadoras do \textit{dataset} HRIPCB.}
  \includegraphics[scale=1]{img/img-resultados-hripcb-notacao.pdf}
  \label{fig:resultados-hripcb-notacao}
  \indentedfont[15.2cm]{Adaptado de \citeonline{ref:Huang-et-al}}
\end{figure}


A estrutura de arquivos do \textit{dataset} está na \autoref{fig:resultados-hripcb-estrutura}. Os arquivos dentro da pasta \textit{rotation} não foram utilizados já que não possuem as delimitações dos defeitos em arquivos de anotação.

\begin{figure}[h!] %H
  \centering
  \caption{Estrutura de arquivos do \textit{dataset} HRIPCB.}
  \includegraphics[scale=0.35]{img/img-resultados-hripcb-estrutura.png}
  \label{fig:resultados-hripcb-estrutura}
  \indentedfont[15.2cm]{\citeonline{ref:Huang-et-al}}
\end{figure}


\section{Configuração dos Arquivos para o Treinamento} \label{cap:treinamento-treinamento-config}

Para o treinamento, é necessário que os arquivos do \textit{dataset} escolhido estejam de acordo com o padrão utilizado pela YOLO e as imagens estejam separadas nos subconjuntos de teste e treinamento.

Os arquivos de anotação do \textit{dataset} HRIPC foram convertidos de \textit{.xml} para \textit{.txt} utilizando o \textit{script} em Python que está no \autoref{apendice:conversao}.
Esse \textit{script} percorre as pastas de anotação de cada defeito (\autoref{fig:resultados-hripcb-estrutura}), abrindo os arquivos \textit{.xml}, convertendo os dados conforme o padrão necessário para o treinamento e salvando esses dados em um arquivo de texto.

A conversão segue as Equações \ref{eq:resultados-conversao-x} e \ref{eq:resultados-conversao-y} para as coordenadas centrais $x_{center}$ e $y_{center}$ das caixas delimitadoras e as Equações \ref{eq:resultados-conversao-w} e \ref{eq:resultados-conversao-h} para a largura ($width$) e altura ($height$) das caixas delimitadoras, onde os resultados estão normalizados pela largura $x_{img}$ e altura  $y_{img}$ da imagem conforme indicado nos passos do \autoref{apendice:etapas-yolo}.

\begin{equation} \label{eq:resultados-conversao-x}
\mathrm{
  x_{center} = \frac{1}{x_{img}} \cdot ( x_{min} + \frac{x_{max} - x_{min}}{2})
}
\end{equation}

\begin{equation} \label{eq:resultados-conversao-y}
\mathrm{
  y_{center} = \frac{1}{y_{img}} \cdot ( y_{min} + \frac{y_{max} - y_{min}}{2})
}
\end{equation}

\begin{equation} \label{eq:resultados-conversao-w}
\mathrm{
  width = \frac{1}{x_{img}} \cdot (x_{max} - x_{min})
}
\end{equation}

\begin{equation} \label{eq:resultados-conversao-h}
\mathrm{
  height = \frac{1}{y_{img}} \cdot (y_{max} - y_{min})
}
\end{equation}

Além da conversão das coordenadas da caixa delimitadora, é necessário também especificar de maneira numérica qual é o defeito indicado por ela. Os defeitos estão numerados de acordo com a \autoref{tab:resultados-defeitos}.

\begin{table}[!h]
  \begin{center}
  \caption{Representação dos defeitos do conjunto de dados HRIPCB para o treinamento da Rede Neural.}
  \label{tab:resultados-defeitos}
  \begin{tabular}{cc}
    \toprule
    \textbf{Defeito} & \textbf{Representação Numérica}\\
    \midrule \midrule
    Circuito Aberto     & 1 \\
    Curto-Circuito      & 2 \\
    Falta de Cobre      & 3 \\
    Excesso de Cobre    & 4 \\
    Trilha Desconectada & 5 \\
    Falta de Estanho    & 6 \\
    \bottomrule
  \end{tabular}
  \indentedfont[0.96\textwidth]{Elaboração própria (2021)}
  \end{center}
\end{table}

O resultado da conversão do arquivo de anotação em \textit{.xml} do \autoref{apendice:hripcb-xml} está no \autoref{cod:conv}, onde cada linha representa um defeito suas coordenadas seguindo o padrão indicado por \citeonline{ref:Bochkovskiy} no \autoref{apendice:etapas-yolo}.

\lstinputlisting
[caption=Exemplo de arquivo de anotação para treinamento com YOLO.,
label=lst:hripcb,
firstnumber=1,
label=cod:conv]
{cod/anotacoes-HRIPCB.txt}

O \textit{dataset} foi dividido aleatoriamente nos sub-conjuntos treinamento e teste utilizando o \textit{script} do \autoref{apendice:divisao}, com 20\% dos arquivos para testes e o restante para o treinamento. Esse \textit{script} separa tanto as imagens quanto os arquivos de anotação e, além disso, também é responsável por criar os arquivos de texto \textit{train.txt} e \textit{test.txt} que lista todos os arquivos de cada subconjunto de treinamento e testes, respectivamente, necessários para o treinamento com YOLO.

O arquivo de configuração \textit{obj.data} é o apresendado no \autoref{cod:obj-data}. Esse arquivo contém o número de classes a serem treinadas além dos caminhos para os principais arquivos requeridos para o treinamento. O arquivo \textit{obj.names} está no \autoref{cod:obj-names} que lista todas as classes treinadas.

\lstinputlisting
[caption=Arquivo de configuração \textit{obj.data}.,
firstnumber=1,
label=cod:obj-data]
{cod/obj.data}

\lstinputlisting
[caption=Arquivo de configuração \textit{obj.names}.,
firstnumber=1,
label=cod:obj-names]
{cod/obj.names}

O arquivo de configuração das camadas da rede neural foi ajustado de acordo com o \autoref{apendice:etapas-yolo}. Sendo assim, o número máximo de \textit{batches} necessários para o treinamento foi $n_{classes} \cdot 2000 = 12000$ e a quantidade de filtros considerada foi de $(n_{classes} + 5) \cdot 3 = 33$.

\section{Treinamento} \label{cap:treinamento-treinamento}
O treinamento foi feito no Google Colaboratory, um ambiente que permite a execução de códigos Python em \textit{notebooks} Jupyter, adequado para Aprendizado de Máquina, análise de dados e educação, oferecendo recursos de computação como GPUs de forma gratuita \cite{ref:Colab}.

O código completo utilizado para o treinamento está disponível no \autoref{apendice:treinamento}, contendo todos os comandos utilizados.

O repositório do Darknet, disponibilizado \textit{online} por \citeonline{ref:Bochkovskiy} no endereço \url{https://github.com/AlexeyAB/darknet}, foi adicionado ao ambiente, por meio do comando \textit{git clone}. Além disso, foram manualmente adicionadas as pastas contendo os arquivos de configuração e do \textit{dataset} para o treinamento.

Alterações no arquivo \textit{makefile} foram feitas para que o treinamento ocorresse utilizando GPU (linhas quinze a dezessete do código do \autoref{apendice:treinamento}) e em seguida compilou-se o Darknet para o treinamento.

Com intuído de acelerar o treinamento, utilizou-se a transferência de aprendizado e iniciou-se a rede com os pesos da \textit{yolov4.conv.137}, pré-treinada com um \textit{dataset} contendo mais de um milhão de imagens com objetos classificados em mais mil categorias \cite{ref:Redmon-et-al}. A transferência de aprendizado consiste em acelerar um novo treinamento a partir de resultados obtidos em treinamentos anteriores \cite{ref:Cai-Bileschi-Nielsen}. 

\section{Resultados} \label{cap:treinamento-resultados}
O gráfico da \autoref{fig:resultados-grafico} mostra o resultado das métricas para o início do treinamento. Nota-se que para um pouco mais de mil e duzendos \textit{batches} a métrica de mAP, em vermelho, já estava com pico em 98\%. Da mesma forma, a função de perda, representada pelo traço azul, foi diminuindo consideravelmente conforme o andamento do treinamento.

\begin{figure}[h!] %H
  \centering
  \caption{Estrutura de arquivos do \textit{dataset} HRIPCB.}
  \includegraphics[scale=0.8]{img/img-resultados-grafico.png}
  \label{fig:resultados-grafico}
  \indentedfont[15.2cm]{Elaboração própria (2021)}
\end{figure}

Para dois mil e quinhentos \textit{batches}, os resultados das métricas calculadas estão na \autoref{tab:resultados-metricas}.

\begin{table}[!h]
  \begin{center}
  \caption{Resultados de Precisão Média para as classes treinadas de defeitos em placas de circuito impresso.}
  \label{tab:resultados-metricas}
  \begin{tabular}{cccc}
    \toprule
    \textbf{Defeito} & \textbf{Precisão Média (AP)} \\
    \midrule \midrule
    Circuito Aberto     & 97.07\% \\
    Curto-Circuito      & 98.82\% \\
    Falta de Cobre      & 99.20\%  \\
    Excesso de Cobre    & 96.68\% \\
    Trilha Desconectada & 98.87\% \\
    Falta de Estanho    & 100.00\% \\
    \bottomrule
  \end{tabular}
  \indentedfont[0.96\textwidth]{Elaboração própria (2021)}
  \end{center}
\end{table}

\chapter{Interface de Aplicação} \label{cap:api}
